{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n <br>\n", "Datasets & Dataloaders...<br>\n", "does two things:<br>\n", "1. complies with pytorch dataloader types<br>\n", "2. pairs segmentation mask targets with images<br>\n", "no need for labels, segmentation only.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch.utils.data import Dataset, DataLoader, random_split  # split technique up for discussion\n", "import os\n", "from PIL import Image\n", "import numpy as np\n", "import torch\n", "from torchvision import transforms"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_image(image_path):\n", "    \"\"\"\n", "    Loads an image from path, converts to RGB, and converts to a PyTorch tensor.\n", "    Normalizes to [0, 1] range.\n", "    \n", "    Args:\n", "        image_path: Path to the image file.\n", "        \n", "    Returns:\n", "        A PyTorch tensor of shape (3, height, width)\n", "    \"\"\"\n", "    try:\n", "        img = Image.open(image_path).convert('RGB')\n", "        transform = transforms.Compose([\n", "            transforms.ToTensor(),  # Converts to tensor and scales to [0, 1]\n", "        ])\n", "        return transform(img)\n", "    except Exception as e:\n", "        print(f\"Error loading image {image_path}: {e}\")\n", "        return None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_segmentation_mask(mask_path):\n", "    \"\"\"\n", "    Loads a segmentation mask and converts it to a class index tensor.\n", "    For binary segmentation (foreground/background), creates a tensor of shape (height, width).\n", "    \n", "    Args:\n", "        mask_path: Path to the segmentation mask.\n", "        \n", "    Returns:\n", "        A PyTorch tensor of shape (height, width) with class indices.\n", "    \"\"\"\n", "    try:\n", "        mask = Image.open(mask_path)\n", "        # Convert mask to numpy array\n", "        mask_array = np.array(mask)\n", "        \n", "        # If mask is RGB or RGBA, convert to binary (0/1)\n", "        if len(mask_array.shape) == 3:\n", "            mask_array = (mask_array.sum(axis=2) > 0).astype(np.int64)\n", "        else:\n", "            mask_array = (mask_array > 0).astype(np.int64)\n", "        \n", "        # Convert to tensor (no normalization needed for segmentation masks)\n", "        return torch.from_numpy(mask_array)\n", "    except Exception as e:\n", "        print(f\"Error loading mask {mask_path}: {e}\")\n", "        return None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------------------------------------<br>\n", "get images, works for both segmentations and images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_file_paths(directory):\n", "    \"\"\"\n", "    Get all image file paths from a directory structure.\n", "    \n", "    Args:\n", "        directory: Path to directory containing images (possibly in subdirectories)\n", "        \n", "    Returns:\n", "        List of file paths to images\n", "    \"\"\"\n", "    file_paths = []\n", "    \n", "    for root, _, files in os.walk(directory):\n", "        for file in files:\n", "            if file.endswith(('.png', '.jpg', '.jpeg', '.JPG', '.JPEG', '.PNG')):\n", "                file_paths.append(os.path.join(root, file))\n", "    \n", "    return file_paths"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CUBDataset(Dataset):\n", "    def __init__(self, image_dir, segmentation_dir, transform=None):\n", "        self.image_paths = get_file_paths(image_dir)\n", "        self.segmentation_paths = get_file_paths(segmentation_dir)\n", "        self.transform = transform\n", "        \n", "        # Ensure matching number of images and segmentation masks\n", "        if len(self.image_paths) != len(self.segmentation_paths):\n", "            raise ValueError(f\"Number of images ({len(self.image_paths)}) doesn't match number of segmentations ({len(self.segmentation_paths)})\")\n", "            \n", "        print(f\"Dataset loaded with {len(self.image_paths)} image-segmentation pairs\")\n", "    def __len__(self):\n", "        return len(self.image_paths)\n", "    def __getitem__(self, idx):\n", "        # Load image and convert to tensor\n", "        image = load_image(self.image_paths[idx])\n", "        \n", "        # Load segmentation mask and convert to tensor\n", "        segmentation = load_segmentation_mask(self.segmentation_paths[idx])\n", "        \n", "        # Apply transformations if specified\n", "        if self.transform:\n", "            image = self.transform(image)\n", "            \n", "        return image, segmentation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_train_val_test_loaders(image_dir, segmentation_dir, batch_size=32, \n", "                                 train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n", "    \"\"\"\n", "    Create train, validation, and test DataLoaders with split\n", "    \n", "    Args:\n", "        image_dir: Directory containing images\n", "        segmentation_dir: Directory containing segmentation masks\n", "        batch_size: Batch size for DataLoaders\n", "        train_ratio: Proportion of data for training\n", "        val_ratio: Proportion of data for validation\n", "        test_ratio: Proportion of data for testing\n", "        num_workers: Number of worker processes for data loading\n", "        pin_memory: Whether to pin memory for faster data transfer to GPU\n", "        \n", "    Returns:\n", "        train_loader, val_loader, test_loader\n", "    \"\"\"\n", "    # Create full dataset\n", "    full_dataset = CUBDataset(image_dir, segmentation_dir)\n", "    \n", "    # Calculate split sizes\n", "    total_size = len(full_dataset)\n", "    train_size = int(train_ratio * total_size)\n", "    val_size = int(val_ratio * total_size)\n", "    test_size = total_size - train_size - val_size\n", "    \n", "    # Set a fixed seed for reproducibility\n", "    generator = torch.Generator().manual_seed(42)\n", "    \n", "    # Split dataset\n", "    train_dataset, val_dataset, test_dataset = random_split(\n", "        full_dataset, [train_size, val_size, test_size], generator=generator\n", "    )\n", "    \n", "    # Create DataLoaders\n", "    train_loader = DataLoader(\n", "        train_dataset, \n", "        batch_size=batch_size, \n", "        shuffle=True\n", "    )\n", "    \n", "    val_loader = DataLoader(\n", "        val_dataset, \n", "        batch_size=batch_size, \n", "        shuffle=False\n", "    )\n", "    \n", "    test_loader = DataLoader(\n", "        test_dataset, \n", "        batch_size=batch_size, \n", "        shuffle=False\n", "    )\n", "    \n", "    return train_loader, val_loader, test_loader"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Example usage:<br>\n", "image_dir = os.path.join(\"CUBdata/CUB_200_2011/images/\")<br>\n", "segmentation_dir = os.path.join(\"CUBdata/segmentations/\")<br>\n", "# Create data loaders<br>\n", "train_loader, val_loader, test_loader = create_train_val_test_loaders(<br>\n", "    image_dir=image_dir,<br>\n", "    segmentation_dir=segmentation_dir,<br>\n", "    batch_size=1<br>\n", ")<br>\n", "# Test loading a batch<br>\n", "for images, masks in train_loader:<br>\n", "    print(f\"Image batch shape: {images.shape}\")<br>\n", "    print(f\"Mask batch shape: {masks.shape}\")<br>\n", "    break<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["path_images_folder = os.path.join(\"CUBdata/CUB_200_2011/images/\")\n", "path_segmentations_folder = os.path.join(\"CUBdata/segmentations/\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader, val_loader, test_loader = create_train_val_test_loaders(\n", "    image_dir=path_images_folder,\n", "    segmentation_dir=path_segmentations_folder,\n", "    batch_size=1\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for images, masks in train_loader:\n", "    print(f\"Image batch shape: {images.shape}\")\n", "    print(f\"Mask batch shape: {masks.shape}\")\n", "    break"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}